# Building a Resume Parser Using NLP(Spacy) and Machine Learning

## Introduction

Gone are the days when recruiters used to manually screen resumes for a long time. Sifting through thousands of candidates’ resumes for a job is no more a challenging task- all thanks to resume parsers. Resume parsers use machine learning technology to help recruiters search thousands of resumes in an intelligent manner so they can screen the right candidate for a job interview.

## What is a Resume Parser?
A resume parser or a CV parser is a program that analyses and extracts CV/ Resume data according to the job description and returns machine-readable output that is suitable for storage, manipulation, and reporting by a computer. A resume parser stores the extracted information for each resume with a unique entry thereby helping recruiters get a list of relevant candidates for a specific search of keywords and phrases (skills). Resume parsers help recruiters set a specific criterion for a job, and candidate resumes that do not match the set criteria are filtered out automatically. 

In this data science project, you will build an NLP algorithm that parses a resume and looks for the words (skills) mentioned in the job description. You will use the Phrase Matcher feature of the NLP library Spacy that does “word/phrase” matching for the resume documents. The resume parser then counts the occurrence of words (skills) under various categories for each resume that helps recruiters screen ideal candidates for a job.

## Modelling Insurance Claim Severity
Filing insurance claims and dealing with all the paperwork with an insurance broker or an agent is something that nobody wants to drain their time and energy on. To make the insurance claims process hassle-free, insurance companies across the globe are leveraging data science and machine learning to make this claims service process easier. This beginner-level data science project is about how insurance companies are predictive machine learning models to enhance customer service and make the claims service process smoother and faster.

Whenever a person files an insurance claim, an insurance agent reviews all the paperwork thoroughly and then decides on the claim amount to be sanctioned. This entire paperwork process to predict the cost and severity of the claim is time-taking. In this project, you will build a machine learning model to predict the claim severity based on the input data.

This project will make use of the Allstate Claims dataset that consists of 116 categorical variables and 14 continuous features, with over 300,000 rows of masked and anonymous data where each row represents an insurance claim.


